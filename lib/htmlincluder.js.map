{"version":3,"sources":["webpack:///webpack/bootstrap","webpack:///./src/config.js","webpack:///./src/index.js","webpack:///./src/parse.js"],"names":["installedModules","__webpack_require__","moduleId","exports","module","i","l","modules","call","m","c","d","name","getter","o","Object","defineProperty","enumerable","get","r","Symbol","toStringTag","value","t","mode","__esModule","ns","create","key","bind","n","object","property","prototype","hasOwnProperty","p","s","wrapFiles","insertFiles","pageFiles","options","devOptions","insertPattern","filePathAttribute","jsonPathAttribute","configureFiles","file","path","push","setOptions","ops","dev","_config","_parse","initialize","hashFile","f","formatFile","processClip","buildFileResult","callback","map","processedFile","processFile","jsonInput","content","processed","isWin","test","process","platform","contents","toString","trim","split","length","indexOf","splice","tmp","getDefaultNode","type","originalContent","parent","innerScope","children","nestedNodes","attributes","json","topNode","processNode","node","contentArr","splitContent","filter","buildNodes","resolveNode","closeTag","nodes","shift","findNodeType","slice","console","warn","forEach","joinContent","processor","nodeProcessors","loadNodeAttributes","nodeAttributes","reduce","acc","attr","hasTagAttribute","getTagAttribute","processRawJson","nodeList","join","textContent","insert","_node$attributes","jsonPath","rawJson","filename","buildPathFromRelativePath","insertFile","newInnerScope","getDataFromJsonPath","insertNode","wrap","_node$attributes2","childNode","wrapFile","wrapNode","middle","data","_node$attributes3","defaultVal","default","jsonInsert","each","_node$attributes4","count","Array","isArray","values","jsonData","tmpContent","_loop","tmpChildren","_extends","_typeof","if","_node$attributes5","tag","arr","openNdx","partial","startPattern","closeNdx","getIndexOfClosingBrace","endPattern","tagDepth","substr","nextCloseNdx","nextOpenNdx","trace","tmpOpen","tmpClosed","error","result","cur","toSafeJsonString","fixFilePathForOS","replace","cdir","fdir","dirChar","dir","pop","e","jsonObj","JSON","stringify","jsonString","eval","fndx","lndx"],"mappings":"6DACA,IAAAA,EAAA,GAGA,SAAAC,EAAAC,GAGA,GAAAF,EAAAE,GACA,OAAAF,EAAAE,GAAAC,QAGA,IAAAC,EAAAJ,EAAAE,GAAA,CACAG,EAAAH,EACAI,GAAA,EACAH,QAAA,IAUA,OANAI,EAAAL,GAAAM,KAAAJ,EAAAD,QAAAC,IAAAD,QAAAF,GAGAG,EAAAE,GAAA,EAGAF,EAAAD,QA0DA,OArDAF,EAAAQ,EAAAF,EAGAN,EAAAS,EAAAV,EAGAC,EAAAU,EAAA,SAAAR,EAAAS,EAAAC,GACAZ,EAAAa,EAAAX,EAAAS,IACAG,OAAAC,eAAAb,EAAAS,EAAA,CAA0CK,YAAA,EAAAC,IAAAL,KAK1CZ,EAAAkB,EAAA,SAAAhB,GACA,oBAAAiB,eAAAC,aACAN,OAAAC,eAAAb,EAAAiB,OAAAC,YAAA,CAAwDC,MAAA,WAExDP,OAAAC,eAAAb,EAAA,cAAiDmB,OAAA,KAQjDrB,EAAAsB,EAAA,SAAAD,EAAAE,GAEA,GADA,EAAAA,IAAAF,EAAArB,EAAAqB,IACA,EAAAE,EAAA,OAAAF,EACA,KAAAE,GAAA,iBAAAF,QAAAG,WAAA,OAAAH,EACA,IAAAI,EAAAX,OAAAY,OAAA,MAGA,GAFA1B,EAAAkB,EAAAO,GACAX,OAAAC,eAAAU,EAAA,WAAyCT,YAAA,EAAAK,UACzC,EAAAE,GAAA,iBAAAF,EAAA,QAAAM,KAAAN,EAAArB,EAAAU,EAAAe,EAAAE,EAAA,SAAAA,GAAgH,OAAAN,EAAAM,IAAqBC,KAAA,KAAAD,IACrI,OAAAF,GAIAzB,EAAA6B,EAAA,SAAA1B,GACA,IAAAS,EAAAT,KAAAqB,WACA,WAA2B,OAAArB,EAAA,SAC3B,WAAiC,OAAAA,GAEjC,OADAH,EAAAU,EAAAE,EAAA,IAAAA,GACAA,GAIAZ,EAAAa,EAAA,SAAAiB,EAAAC,GAAsD,OAAAjB,OAAAkB,UAAAC,eAAA1B,KAAAuB,EAAAC,IAGtD/B,EAAAkC,EAAA,IAIAlC,IAAAmC,EAAA,mFClFO,IAAMC,cAAY,GACZC,gBAAc,GACdC,cAAY,GAEdC,YAAU,GACVC,aAAa,GACbC,uBACAC,2BACAC,2BAEEC,iBAAiB,SAAAC,GACR,MAAjBA,EAAKlC,KAAK,GACXyB,EAAUS,EAAKC,MAAQD,EACA,MAAjBA,EAAKlC,KAAK,GAChB0B,EAAYQ,EAAKC,MAAQD,EAEzBP,EAAUS,KAAKF,IAiBNG,aAAa,SAAAC,GACxB/C,EA7BSsC,WA6BIS,EAAIC,KAAO,GACxBhD,EA/BSqC,QA+BTA,EAAUU,EAGV/C,EAhCSuC,cAgCQF,EAAQE,cACrB,WAAUF,EAAQE,cAClB,iBAEJvC,EAnCSwC,kBAmCYH,EAAQG,kBACzBH,EAAQG,kBACR,OAEJxC,EAtCSyC,kBAsCYJ,EAAQI,kBACzBJ,EAAQI,kBACR,0CChDN,IAAAQ,EAAAnD,EAAA,GACAoD,EAAApD,EAAA,GAEAG,EAAOD,QAAU,CACfmD,WAAa,SAAAd,GAAA,OAAW,EAAAY,EAAAH,YAAWT,IAEnCe,SAAW,SAAAT,GACT,IAAMU,EAAIC,EAAWX,GAGrBY,EAAYF,IAEZ,EAAAJ,EAAAP,gBAAeW,IAGjBG,gBAAkB,SAAAC,GAAA,OAAYR,EAAAb,UAAUsB,IAAI,SAAAf,GAC1C,IAAMgB,GAAgB,EAAAT,EAAAU,aAAYjB,EAAMM,EAAAZ,QAAQwB,WAAa,IAQ7D,OAPAlB,EAAKmB,QAAUH,EAAcG,QAE7BnB,EAAKoB,WAAY,EAEdN,GACDA,EAASd,GAEJA,MAIX,IAAMqB,EAAQ,OAAOC,KAAKC,QAAQC,UAE5Bb,EAAa,SAAAX,GACjB,IAAIU,EAAI,CACNT,KAAOD,EAAKC,KACZkB,QAAUnB,EAAKyB,SAASC,SAAS,QAAQC,OACzCP,WAAY,EACZpB,KAAOA,GAMT,OAHAU,EAAE5C,KAAQuD,EAASrB,EAAKC,KAAK2B,MAAM,MAAQ5B,EAAKC,KAAK2B,MAAM,KAC3DlB,EAAE5C,KAAO4C,EAAE5C,KAAK4C,EAAE5C,KAAK+D,OAAO,GAEvBnB,GAIHE,EAAc,SAAAZ,GAWlB,GATGA,EAAKmB,QAAQW,QAAQ,uBAAsB,IAC5C9B,EAAKmB,QAAUnB,EAAKmB,QACjBS,MAAM,yBACNG,OAAO,GAAG,GACVH,MAAM,qBACNG,OAAO,EAAE,GAAG,IAId/B,EAAKmB,QAAQW,QAAQ,wBAAuB,EAAG,CAChD,IAAME,EAAMhC,EAAKmB,QAAQS,MAAM,0BAC/B5B,EAAKmB,QAAUa,EAAI,GAAKA,EAAI,GAAGJ,MAAM,6BAA6B,mhBC1DtEtB,QAAAnD,oBAAA,GAWM8E,eAAiB,iBAAO,CAC5BC,KAAkB,GAClBlC,KAAkB,GAClBmC,gBAAkB,GAClBhB,QAAkB,GAClBiB,OAAkB,GAClBC,WAAkB,KAClBC,SAAkB,GAClBC,YAAkB,GAClBC,WAAkB,KAIPvB,gCAAc,SAACjB,EAAMyC,EAAML,EAAQC,GAE9C,IAAMK,cACDT,iBADC,CAEJC,KAAU,UACVlC,OACAmC,gBAAiBnC,EAAKmB,QACtBA,QAAUnB,EAAKmB,SACXiB,EAAa,CAAEA,UAAe,GAC9BC,EAAa,CAAEA,cAAe,IAIpC,OAAiD,IAA9CK,EAAQP,gBAAgBL,QAAQ,YAC1BY,GAGTC,YAAYD,EAASD,GAEdC,IAIHC,YAAc,SAACC,EAAMH,GACzB,GAAiB,gBAAdG,EAAKV,KAAR,CAIA,IAAMW,EAAaC,aAAaF,EAAKzB,SAAS4B,OAAO,SAAAnF,GAAA,MAAW,KAANA,IAG1DgF,EAAKL,YAAcS,WAAWJ,EAAMC,EAAYJ,GAEhDQ,YAAYL,EAAMH,KAIdO,WAAa,SAAbA,EAAcZ,EAAQS,EAAYJ,EAAMS,GAG5C,IAFA,IAAMC,EAAQ,GAERN,EAAWhB,OAAS,GAAG,CAC3B,IAAMV,EAAU0B,EAAWO,QAG3B,GAAGF,GAA0C,IAA9B/B,EAAQW,QAAQoB,GAC7B,OAAOC,EAGT,IAAMjB,EAAOmB,aAAalC,GAEpByB,cACDX,iBADC,CAEJC,OACAE,SACApC,KAAkBoC,EAAOpC,KACzBqC,WAAkBD,EAAOC,WACzBF,gBAAkBhB,EAClBA,YAIU,gBAATe,GAMHU,EAAKzB,QAAUyB,EAAKT,gBAAgBmB,MAAM,GAM1CV,EAAKN,SACQ,SAATJ,EAAkBc,EAAWJ,EAAMC,EAAYJ,EAAM,mBAC5C,SAATP,EAAkBc,EAAWJ,EAAMC,EAAYJ,EAAM,mBAC5C,OAATP,EAAkBc,EAAWJ,EAAMC,EAAYJ,EAAM,iBACrD,GAGJU,EAAMjD,KAAK0C,IAlBTO,EAAMjD,KAAK0C,GAyBf,OAHGM,GACDK,QAAQC,KAAR,kCAA+CpB,EAAOpC,KAAKC,KAA3D,6BAEKkD,GAIHF,YAAc,SAACL,EAAMH,GAEtBG,EAAKL,YAAYV,OAAS,IAC3Be,EAAKL,YAAYkB,QAAQ,SAAAb,GAAA,OAAQD,YAAYC,EAAMH,KACnDG,EAAKzB,QAAUuC,YAAYd,EAAKL,cAIlC,IAAMoB,EAAYC,eAAehB,EAAKV,MAGlCyB,GAMJf,EAAKJ,WAAaqB,mBAAmBjB,GAErCe,EAAUf,EAAMH,IAPdc,QAAQC,KAAR,kCAA+CZ,EAAK5C,KAAKC,KAAzD,sCAAmG2C,EAAKV,KAAxG,MAWE2B,mBAAqB,SAAAjB,GAEzB,OADckB,eAAelB,EAAKV,OAAS,IAC9B6B,OAAO,SAACC,EAAKC,GACxB,GAAGC,gBAAgBD,EAAMrB,EAAKT,iBAAkB,CAC9C,IAAM3D,EAAQ2F,gBAAgBF,EAAMrB,EAAKT,iBACzC6B,EAAIC,GAAkB,YAATA,EAAsBG,eAAe5F,GAASA,EAE7D,OAAOwF,GACN,KAICX,aAAe,SAAAlC,GAAA,OACoB,IAAvCA,EAAQW,QAAQ,kBAA2B,SACJ,IAAvCX,EAAQW,QAAQ,gBAA2B,OACJ,IAAvCX,EAAQW,QAAQ,sBAA2B,aACJ,IAAvCX,EAAQW,QAAQ,gBAA2B,OACJ,IAAvCX,EAAQW,QAAQ,kBAA2B,SACJ,IAAvCX,EAAQW,QAAQ,gBAA2B,OACJ,IAAvCX,EAAQW,QAAQ,cAA2B,KAC3C,eAII4B,YAAc,SAAAW,GAAA,OAAYA,EAAStD,IAAI,SAAAnD,GAAA,OAAKA,EAAEuD,UAASmD,KAAK,KAI5DV,eAAiB,CAErBlB,QAAU,SAACE,EAAMH,GAAP,OAAgBG,EAAKzB,QAAUuC,YAAYd,EAAKL,cAE1DgC,YAAc,SAAC3B,EAAMH,GAAP,OAAgBc,QAAQC,KAAK,kDAE3CgB,OAAS,SAAC5B,EAAMH,GAAS,IACfzC,EAAqB4C,EAArB5C,KAAMqC,EAAeO,EAAfP,WADSoC,EAEa7B,EAAKJ,WAAjCvC,EAFewE,EAEfxE,KAAMyE,EAFSD,EAETC,SAAUC,EAFDF,EAECE,QACxB,IAAI1E,EAGF,OAFAsD,QAAQC,KAAR,kCAA+CxD,EAAKC,KAApD,6CACA2C,EAAKzB,QAAU,IAKjB,IAAMyD,EAAWC,0BAA0B7E,EAAKC,KAAMA,GAGtD,IAAIK,QAAAd,YAAYoF,GAGd,OAFArB,QAAQC,KAAR,kCAA+CxD,EAAKC,KAApD,mBAA2E2E,EAA3E,yBACAhC,EAAKzB,QAAU,IAKjB,IAAM2D,cAAkBxE,QAAAd,YAAYoF,IAG9BG,EACFJ,GAAcD,EAAWM,oBAAoBN,EAAUC,GACvDtC,GAAcqC,EAAWM,oBAAoBN,EAAUrC,GACvDsC,IACAD,EAAWM,oBAAoBN,EAAUjC,QACzC,GAGEwC,EAAahE,YAAY6D,EAAYrC,EAAMG,EAAMmC,GAGvDnC,EAAKzB,QAAU8D,EAAW9D,SAG5B+D,KAAO,SAACtC,EAAMH,GAAS,IACbzC,EAAqB4C,EAArB5C,KAAMqC,EAAeO,EAAfP,WADO8C,EAEevC,EAAKJ,WAAjCvC,EAFakF,EAEblF,KAAMyE,EAFOS,EAEPT,SAAUC,EAFHQ,EAEGR,QACxB,IAAI1E,EAGF,OAFAsD,QAAQC,KAAR,kCAA+CZ,EAAK5C,KAAKC,KAAzD,2CACA2C,EAAKzB,QAAU,IAKjB,IAAMyD,EAAWC,0BAA0B7E,EAAKC,KAAMA,GAGtD,IAAIK,QAAAf,UAAUqF,GAGZ,OAFArB,QAAQC,KAAR,kCAA+CZ,EAAK5C,KAAKC,KAAzD,iBAA8E2E,EAA9E,yBACAhC,EAAKzB,QAAU,IAOjByB,EAAKN,SAASmB,QAAQ,SAAA2B,GAAA,OAAazC,YAAYyC,EAAW3C,KAC1DG,EAAKzB,QAAUuC,YAAYd,EAAKN,UAGhC,IAAM+C,cAAgB/E,QAAAf,UAAUqF,IAG1BG,EACFJ,GAAcD,EAAWM,oBAAoBN,EAAUC,GACvDtC,GAAcqC,EAAWM,oBAAoBN,EAAUrC,GACvDsC,IACAD,EAAWM,oBAAoBN,EAAUjC,QACzC,GAGE6C,EAAWrE,YAAYoE,EAAU5C,EAAMG,EAAMmC,GAGnDnC,EAAKzB,QAAUmE,EAASnE,SAG1BoE,OAAS,SAAC3C,EAAMH,GAAP,OAAgBG,EAAKzB,QAAUyB,EAAKR,OAAOA,OAAOjB,SAE3DqE,KAAO,SAAC5C,EAAMH,GAAS,IACbJ,EAAqBO,EAArBP,WAAYrC,EAAS4C,EAAT5C,KADCyF,EAES7C,EAAKJ,WAA3BkC,EAFae,EAEbf,SAAUC,EAFGc,EAEHd,QACZe,EAAa9C,EAAKJ,WAAWmD,QACnC,IAAIjB,IAAcC,IAAYtC,IAAeqD,EAG3C,OAFAnC,QAAQC,KAAR,kCAA+CxD,EAAKC,KAApD,oDAA4G2C,EAAKT,gBAAjH,UACAS,EAAKzB,QAAU,IAGjB,IACMqE,EAAOR,oBAAoBN,EADlBC,GAAWtC,GAE1BO,EAAKzB,QAAUqE,GAAQE,GAAc,IAGvCE,WAAa,SAAChD,EAAMH,GAAS,IACnBiC,EAAa9B,EAAKJ,WAAlBkC,SACFgB,EAAa9C,EAAKJ,WAAWmD,QACnC,GAAIjB,EAAJ,CAIA,IAAMc,EAAOR,oBAAoBN,EAAUjC,GAC3CG,EAAKzB,QAAUqE,GAAQE,GAAc,QAJnC9C,EAAKzB,QAAU,IAOnB0E,KAAO,SAACjD,EAAMH,GAAS,IACbzC,EAAqB4C,EAArB5C,KAAMqC,EAAeO,EAAfP,WADOyD,EAEgBlD,EAAKJ,WAAlCuD,EAFaD,EAEbC,MAAOrB,EAFMoB,EAENpB,SAAUC,EAFJmB,EAEInB,QACzB,KAAIoB,GAAUrB,GAAasB,MAAMC,QAAQtB,IAAaqB,MAAMC,QAAQ5D,IAGlE,OAFAkB,QAAQC,KAAR,kCAA+CxD,EAAKC,KAApD,uGACA2C,EAAKzB,QAAU,IAKjB,IAAM+E,EAASvB,GAAW/B,EAAKP,YAAcI,EACvC0D,EAAWzB,EAAWM,oBAAoBN,EAAUwB,QAAU,EAC9DV,EACFQ,MAAMC,QAAQC,GAAYA,EAC1BF,MAAMC,QAAQE,GAAYA,OAC1B,EAGJ,GAAIX,GAASO,EAAb,CAOA,IADA,IAAMK,EAAa,GAxBEC,EAAA,SA0Bf9I,GAMJ,IAAM+I,EAAc1D,EAAKN,SAASvB,IAAI,SAAAnD,GAAA,OAAA2I,SAAA,GACjC3I,EACC4H,EACA,CACEnD,WAAkC,WAApBmE,QAAOhB,EAAKjI,IAAbgJ,SAAA,GAAsCf,EAAKjI,IAAOiI,EAAKjI,IAEtE,MAGN+I,EAAY7C,QAAQ,SAAA2B,GAAA,OAAazC,YAAYyC,EAAW3C,KACxD2D,EAAWlG,KAAKwD,YAAY4C,KAhBxB/I,EAAI,IACHwI,GAAUA,GAASxI,EAAIwI,MACvBP,GAAUA,GAASjI,EAAIiI,EAAK3D,QACjCtE,IACF8I,EAJM9I,GAmBNqF,EAAKzB,QAAUiF,EAAW9B,KAAK,SA1B7B1B,EAAKzB,QAAU,IA6BnBsF,GAAK,SAAC7D,EAAMH,GAAS,IACXJ,EAAeO,EAAfP,WADWqE,EAEW9D,EAAKJ,WAA3BkC,EAFWgC,EAEXhC,SAAUC,EAFC+B,EAED/B,QACdD,EAMaM,oBAAoBN,EADtBC,GAAWtC,GAAcI,IAQxCG,EAAKN,SAASmB,QAAQ,SAAA2B,GACpBA,EAAU/C,WAAVkE,SAAA,GAA4B3D,EAAKP,YACjCM,YAAYyC,EAAW3C,KAEzBG,EAAKzB,QAAUuC,YAAYd,EAAKN,WAR9BM,EAAKzB,QAAU,GARfyB,EAAKzB,QAAU,KAqBf2C,eAAiB,CACrBU,OAAc,CAAE,OAAQ,WAAY,WACpCgB,KAAc,CAAE,WAAY,UAAW,WACvCI,WAAc,CAAE,WAAY,WAC5BV,KAAc,CAAE,OAAQ,WAAY,WACpCK,OAAc,GACdM,KAAc,CAAE,QAAS,WAAY,WACrCY,GAAc,CAAE,WAAY,WAC5BlC,YAAc,IAKVzB,aAAe,SAAC3B,EAASwF,GAC7B,IAAIC,EAAM,GACNC,GAAW,EAEXC,EAAU,GACVC,EAAeJ,GAAO,WAM1B,IAAgB,KAFhBE,EAAU1F,EAAQW,QAAQiF,IAGxB,MAAO,CAAC5F,GAEV,KAAM0F,GAAW,GAAG,EAClBC,EAAU3F,EAAQmC,MAAM,EAAGuD,KAEzBD,EAAI1G,KAAK4G,GAEX3F,EAAUA,EAAQmC,MAAMuD,GAIxB,IAAIG,EAAWC,uBAAuB9F,EAAS4F,EAjBhC,UAmBfD,EAAU3F,EAAQmC,MAAM,EAAG0D,GAC3BJ,EAAI1G,KAAK4G,IAOO,KAHhBD,GAHA1F,EAAUA,EAAQmC,MAAM0D,IAGNlF,QAAQiF,KAIxBH,EAAI1G,KAAKiB,GAIb,OAAOyF,GAIHK,uBAAyB,SAAC9F,EAAS4F,EAAcG,GACrD,IAAIC,EAAW,EACXf,EAAajF,EAAQiG,OAAO,GAI5BC,EAAejB,EAAWtE,QAAQoF,GAClCI,EAAclB,EAAWtE,QAAQiF,GAMrC,IAJsB,IAAnBM,GACD9D,QAAQgE,MAAR,kCAAgDR,EAAhD,oBAAgFG,EAAhF,iBAA2G/F,IAGzF,IAAjBmG,GAAsBA,EAAcD,EACrC,OAAOA,EAAe,EAGxBC,GAAe,EACfD,GAAgB,EAGhB,EAAG,CACD,IAAIG,SAASC,SAIb,GAAGH,GAAe,GAAKA,EAAcD,GACnCG,EAAUpB,EAAWgB,OAAOE,GAAaxF,QAAQiF,KAEnC,GAEZO,GAAeE,EAAU,EACzBL,GAAY,GAGZG,GAAe,OAKjB,IAFAG,EAAYrB,EAAWgB,OAAOC,GAAcvF,QAAQoF,KAEpC,GAKd,GAHAG,GAAgBI,EAAY,EAGZ,KAFhBN,GAAY,GAGV,OAAOE,EAAe,OAErB,GAAGF,EAAW,EAAG,CACpB5D,QAAQmE,MAAR,gDAA8DvG,GAC9D,aAGEgG,EAAW,GAOnB,OAHqB,KAFrBE,GAAgB,IAGd9D,QAAQmE,MAAR,6CAA2DR,EAA3D,KAEKG,GAIHrC,oBAAsB,SAACN,EAAUjC,GACrC,GAAgB,SAAbiC,EAAqB,OAAOjC,EAE/B,IAAIkF,EAASjD,EAAS9C,MAAM,KAAKmC,OAAO,SAACC,EAAK4D,GAAN,OAAc5D,EAAMA,EAAI4D,GAAO,IAAInF,GAK3E,OAHIuD,MAAMC,QAAQ0B,IAA8B,iBAAnB,IAAOA,EAAP,YAAAnB,QAAOmB,MAClCA,EAASE,iBAAiBF,IAErBA,GAIHtG,MAAQ,OAAOC,KAAKC,QAAQC,UAG5BsG,iBAAmB,SAAA7H,GAAA,OACtBoB,MAASpB,EAAK8H,QAAQ,MAAO,MAAQ9H,EAAK8H,QAAQ,MAAO,MAItDlD,0BAA4B,SAACmD,EAAMC,GACvC,IAAIC,EAAW7G,MAAS,KAAO,IAC3B8G,EAAMH,EAAKpG,MAAMsG,GAWrB,OAVAC,EAAIC,OAEJH,EAAOH,iBAAiBG,IAEnBrG,MAAMsG,GACRzE,QAAQ,SAAS4E,GACT,OAANA,EAAcF,EAAIC,MAAe,MAANC,GAAmB,KAANA,GAAYF,EAAIjI,KAAKmI,KAElEF,EAAMA,EAAI7D,KAAK4D,IAMXL,iBAAmB,SAAAS,GAAA,OACvBC,KAAKC,UAAUF,GAASP,QAAQ,MAAO,OAAOA,QAAQ,KAAM,MAGxD3D,eAAiB,SAAjBA,eAAiBqE,YACK,iBAAvB,IAAOA,WAAP,YAAAjC,QAAOiC,eACRA,WAAaZ,iBAAiBY,aAEhC,IAAItC,SAAW,GACf,IACEuC,KAAK,cAAgBD,YAEvB,MAAMJ,GACJ9E,QAAQmE,MAAR,kDACIe,WADJ,gDAMF,OAAOtC,UAIHjC,gBACJ,SAACD,EAAM9C,GAAP,OAAmBA,EAAQW,QAAQmC,EAAO,OAAS,GAG/CE,gBAAkB,SAACF,EAAM9C,GAC7B,IAAIwH,EACAC,EAGJ,OAAa,KADbD,EAAOxH,EAAQW,QAAQmC,EAAO,QAE5BV,QAAQC,KAAK,4BAA8BS,EAAO,sCAAwC9C,EAAU,KAC7F,KAITyH,GADAzH,EAAUA,EAAQmC,MAAMqF,EAAO1E,EAAKpC,OAAS,IAC9BC,QAAQ,KACvBX,EAAUA,EAAQmC,MAAM,EAAGsF","file":"htmlincluder.js","sourcesContent":[" \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"/\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 1);\n","export const wrapFiles = {};\nexport const insertFiles = {};\nexport const pageFiles = [];\n\nexport let options = {};\nexport let devOptions = {};\nexport let insertPattern;\nexport let filePathAttribute;\nexport let jsonPathAttribute;\n\nexport const configureFiles = file => {\n  if(file.name[0] === '_')\n    wrapFiles[file.path] = file;\n  else if(file.name[0] === '-')\n    insertFiles[file.path] = file;\n  else\n    pageFiles.push(file);\n}\n\n// @options = (optional) options for configuring htmlIncluder\n// options.jsonInput         = A json object used to populate data in files\n// options.insertPattern     = The test looked for in order to insert files\n//          (this is so ssi includes can be used instead)\n// options.filePathAttribute = the name used for the file pathing for #insert\n//          and #wrap (default= 'path')\n// options.jsonPathAttribute = the name used for the file pathing for #insert\n//          , #wrap, #data, #jsonInsert (default= 'jsonPath')\n//\n//\n// options.dev.limitIterations = the number of times processFileWithJsonInput will loop\n// options.dev.printIterations = console log each processFileWithJsonInput loop\n// options.dev.printResult = console logs the final output\n// options.dev.printPaths = console logs the output of buildPathFromRelativePath\nexport const setOptions = ops => {\n  devOptions = ops.dev || {};\n  options = ops;\n\n  //set text value for insert tags, or default\n  insertPattern = (options.insertPattern)\n    ? '<!--#' + options.insertPattern\n    : '<!--#insert';\n\n  filePathAttribute = (options.filePathAttribute)\n    ? options.filePathAttribute\n    : 'path';\n\n  jsonPathAttribute = (options.jsonPathAttribute)\n    ? options.jsonPathAttribute\n    : 'jsonPath';\n}\n","import { configureFiles, setOptions, pageFiles, options } from './config';\nimport { processFile } from './parse';\n\nmodule.exports = {\n  initialize : options => setOptions(options),\n  // puts files into hash maps\n  hashFile : file => {\n    const f = formatFile(file);\n\n    // removing clip right away does no damage and speeds up later processing\n    processClip(f);\n\n    configureFiles(f);\n  },\n  // map on page files and build them into strings\n  buildFileResult : callback => pageFiles.map(file => {\n    const processedFile = processFile(file, options.jsonInput || {});\n    file.content = processedFile.content;\n\n    file.processed = true;\n\n    if(callback)\n      callback(file);\n\n    return file;\n  }),\n};\n\nconst isWin = /^win/.test(process.platform);\n\nconst formatFile = file => {\n  let f = {\n    path : file.path,\n    content : file.contents.toString('utf8').trim(),\n    processed : false,\n    file : file,\n  };\n\n  f.name = (isWin) ? file.path.split('\\\\') : file.path.split('/');\n  f.name = f.name[f.name.length-1];\n\n  return f;\n}\n\n// This runs first, since all of the clipped areas will completely be removed\nconst processClip = file => {\n  // process clipbefore and clipafter\n  if(file.content.indexOf('<!--#clipbefore') > -1) {\n    file.content = file.content\n      .split(/<!--#clipbefore\\s*-->/)\n      .splice(1)[0]\n      .split('<!--#clipafter')\n      .splice(0,1)[0];\n  }\n\n  // process clipbetween\n  if(file.content.indexOf('<!--#clipbetween') > -1) {\n    const tmp = file.content.split(/<!--#clipbetween\\s*-->/);\n    file.content = tmp[0] + tmp[1].split(/<!--#endclipbetween\\s*-->/)[1];\n  }\n}\n","import {\n  jsonPathAttribute,\n  filePathAttribute,\n  insertFiles,\n  wrapFiles,\n  options,\n  devOptions,\n  insertPattern,\n} from './config';\n\n// shape of our AST nodes\nconst getDefaultNode = () => ({\n  type            : '',\n  file            : {},\n  originalContent : '',\n  content         : '',\n  parent          : {},\n  innerScope      : null,\n  children        : [], // list of sequential nodes wrapped in tag (or at topNode)\n  nestedNodes     : [], // nested tags - these need to be resolved before this tag is resolved\n  attributes      : {}, // attributes on tag\n})\n\n// entry point for processing files\nexport const processFile = (file, json, parent, innerScope) => {\n  // convert string into object\n  const topNode = {\n    ...getDefaultNode(),\n    type    : 'topNode',\n    file,\n    originalContent: file.content,\n    content : file.content,\n    ...(parent     ? { parent }     : {}),\n    ...(innerScope ? { innerScope } : {}),\n  };\n\n  // don't do work if there are no tags in the file\n  if(topNode.originalContent.indexOf('<!--#') === -1)\n    return topNode;\n\n  // process children of the node\n  processNode(topNode, json);\n\n  return topNode;\n}\n\n//\nconst processNode = (node, json) => {\n  if(node.type === 'textContent') return;\n\n  // the contents of a node may contain more nested nodes\n  // break these up into an array of mixed textContent nodes and tags\n  const contentArr = splitContent(node.content).filter(c => c !== '');\n\n  // convert array of strings to nodes\n  node.nestedNodes = buildNodes(node, contentArr, json);\n\n  resolveNode(node, json);\n}\n\n//\nconst buildNodes = (parent, contentArr, json, closeTag) => {\n  const nodes = [];\n\n  while(contentArr.length > 0) {\n    const content = contentArr.shift();\n\n    // if we find the close tag, then we are done with our search\n    if(closeTag && content.indexOf(closeTag) === 0)\n      return nodes;\n\n    // lookup type of the tag\n    const type = findNodeType(content);\n\n    const node = {\n      ...getDefaultNode(),\n      type,\n      parent,\n      file            : parent.file,\n      innerScope      : parent.innerScope,\n      originalContent : content,\n      content,\n    };\n\n    // if this is a text node, we're set\n    if(type === 'textContent') {\n      nodes.push(node);\n      continue;\n    }\n\n    // remove leading character ('<') so the inner contents can be parsed properly\n    node.content = node.originalContent.slice(1);\n\n    // the contents inside a node can be treated like new little documents\n\n    // if this is a node that has children build them up, removing them\n    // from the split up array\n    node.children = (\n        type === 'wrap' ? buildNodes(node, contentArr, json, '<!--#endwrap')\n      : type === 'each' ? buildNodes(node, contentArr, json, '<!--#endeach')\n      : type === 'if'   ? buildNodes(node, contentArr, json, '<!--#endif')\n      : []\n    );\n\n    nodes.push(node);\n  }\n\n  // We should never get here while looking for a closing tag\n  if(closeTag)\n    console.warn(`WARNING while processing file '${parent.file.path}': there is a missing tag`);\n\n  return nodes;\n}\n\n//\nconst resolveNode = (node, json) => {\n  // resolve nested tags\n  if(node.nestedNodes.length > 0) {\n    node.nestedNodes.forEach(node => processNode(node, json));\n    node.content = joinContent(node.nestedNodes);\n  }\n\n  // process node so that content is resolved\n  const processor = nodeProcessors[node.type];\n\n  // There is a problem if we found no processor\n  if(!processor) {\n    console.warn(`WARNING while processing file '${node.file.path}': there is no processor for type '${node.type}'`);\n    return;\n  }\n\n  // load and resolve attribute values\n  node.attributes = loadNodeAttributes(node);\n\n  processor(node, json);\n}\n\n// loads values for tags into node object\nconst loadNodeAttributes = node => {\n  const attrs = nodeAttributes[node.type] || [];\n  return attrs.reduce((acc, attr) => {\n    if(hasTagAttribute(attr, node.originalContent)) {\n      const value = getTagAttribute(attr, node.originalContent);\n      acc[attr] = (attr === 'rawJson') ? processRawJson(value) : value;\n    }\n    return acc;\n  }, {})\n}\n\n// check for tag and return node type\nconst findNodeType = content => (\n  content.indexOf('<!--#insert')     === 0 ? 'insert'\n: content.indexOf('<!--#data')       === 0 ? 'data'\n: content.indexOf('<!--#jsonInsert') === 0 ? 'jsonInsert'\n: content.indexOf('<!--#wrap')       === 0 ? 'wrap'\n: content.indexOf('<!--#middle')     === 0 ? 'middle'\n: content.indexOf('<!--#each')       === 0 ? 'each'\n: content.indexOf('<!--#if')         === 0 ? 'if'\n: 'textContent'\n)\n\n//\nconst joinContent = nodeList => nodeList.map(c => c.content).join('')\n\n// the functions that processes each node\n// these assume that they have all their nested nodes resolved and attributes loaded\nconst nodeProcessors = {\n  //\n  topNode : (node, json) => node.content = joinContent(node.nestedNodes),\n  //\n  textContent : (node, json) => console.warn('WARNING: Why are we processing a textContent?'),\n  //\n  insert : (node, json) => {\n    const { file, innerScope } = node;\n    const { path, jsonPath, rawJson } = node.attributes;\n    if(!path) {\n      console.warn(`WARNING while processing file '${file.path}': insert tag with no path attribute`);\n      node.content = '';\n      return;\n    }\n\n    // get filename for inserted file\n    const filename = buildPathFromRelativePath(file.path, path);\n\n    // see if file we are loading exists\n    if(!insertFiles[filename]) {\n      console.warn(`WARNING while processing file '${file.path}': insert file '${filename}' does not exist`);\n      node.content = '';\n      return;\n    }\n\n    // load contents from file\n    const insertFile = { ...insertFiles[filename] };\n\n    // set scope for inserted file\n    const newInnerScope = (\n        rawJson    && jsonPath ? getDataFromJsonPath(jsonPath, rawJson)\n      : innerScope && jsonPath ? getDataFromJsonPath(jsonPath, innerScope)\n      : rawJson  ? rawJson\n      : jsonPath ? getDataFromJsonPath(jsonPath, json)\n      : void(0)\n    );\n\n    const insertNode = processFile(insertFile, json, node, newInnerScope);\n\n    // process contents to get children\n    node.content = insertNode.content;\n  },\n  //\n  wrap : (node, json) => {\n    const { file, innerScope } = node;\n    const { path, jsonPath, rawJson } = node.attributes;\n    if(!path) {\n      console.warn(`WARNING while processing file '${node.file.path}': wrap tag with no path attribute`);\n      node.content = '';\n      return;\n    }\n\n    // get filename for inserted file\n    const filename = buildPathFromRelativePath(file.path, path);\n\n    // see if file we are loading exists\n    if(!wrapFiles[filename]) {\n      console.warn(`WARNING while processing file '${node.file.path}': wrap file '${filename}' does not exist`);\n      node.content = '';\n      return;\n    }\n\n    // we need to process the children before we bring in the file\n\n    // handle children content\n    node.children.forEach(childNode => processNode(childNode, json))\n    node.content = joinContent(node.children);\n\n    // load contents from file\n    const wrapFile = { ...wrapFiles[filename] };\n\n    // set scope for inserted file\n    const newInnerScope = (\n        rawJson    && jsonPath ? getDataFromJsonPath(jsonPath, rawJson)\n      : innerScope && jsonPath ? getDataFromJsonPath(jsonPath, innerScope)\n      : rawJson  ? rawJson\n      : jsonPath ? getDataFromJsonPath(jsonPath, json)\n      : void(0)\n    );\n\n    const wrapNode = processFile(wrapFile, json, node, newInnerScope);\n\n    // process contents to get children\n    node.content = wrapNode.content;\n  },\n  //\n  middle : (node, json) => node.content = node.parent.parent.content,\n  //\n  data : (node, json) => {\n    const { innerScope, file } = node;\n    const { jsonPath, rawJson } = node.attributes;\n    const defaultVal = node.attributes.default;\n    if(!jsonPath || (!rawJson && !innerScope && !defaultVal)) {\n      console.warn(`WARNING while processing file '${file.path}': data tag with no data to look up for content '${node.originalContent}'`);\n      node.content = '';\n      return;\n    }\n    const values = rawJson || innerScope;\n    const data = getDataFromJsonPath(jsonPath, values);\n    node.content = data || defaultVal || '';\n  },\n  //\n  jsonInsert : (node, json) => {\n    const { jsonPath } = node.attributes;\n    const defaultVal = node.attributes.default;\n    if(!jsonPath) {\n      node.content = '';\n      return;\n    }\n    const data = getDataFromJsonPath(jsonPath, json);\n    node.content = data || defaultVal || '';\n  },\n  //\n  each : (node, json) => {\n    const { file, innerScope } = node;\n    const { count, jsonPath, rawJson } = node.attributes;\n    if(!count && !jsonPath && !Array.isArray(rawJson) && !Array.isArray(innerScope)) {\n      console.warn(`WARNING while processing file '${file.path}': each tag with attribute problems: count, jsonPath and rawJson and innerScope are not arrays`);\n      node.content = '';\n      return;\n    }\n\n    // determine what data we are using\n    const values = rawJson || node.innerScope || json;\n    const jsonData = jsonPath ? getDataFromJsonPath(jsonPath, values) : void(0);\n    const data = (\n        Array.isArray(values)   ? values\n      : Array.isArray(jsonData) ? jsonData\n      : void(0)\n    );\n\n    if(!data && !count) {\n      node.content = '';\n      return;\n    }\n\n    // build up nodes and bind the correct data\n    const tmpContent = [];\n    for(\n      let i = 0;\n         (!count || (count && i < count))\n      && (!data  || (data  && i < data.length));\n      i++)\n    {\n      // clone children\n      const tmpChildren = node.children.map(c => ({\n        ...c,\n        ...(data\n          ? {\n              innerScope : (typeof(data[i]) === 'object') ? { ...data[i] } : data[i]\n            }\n          : { }),\n      }))\n      // handle children content\n      tmpChildren.forEach(childNode => processNode(childNode, json))\n      tmpContent.push(joinContent(tmpChildren));\n    }\n\n    node.content = tmpContent.join('');\n  },\n  //\n  if : (node, json) => {\n    const { innerScope } = node;\n    const { jsonPath, rawJson } = node.attributes;\n    if(!jsonPath) {\n      node.content = '';\n      return;\n    }\n\n    const values = rawJson || innerScope || json;\n    const jsonData = getDataFromJsonPath(jsonPath, values);\n\n    if(!jsonData) {\n      node.content = '';\n      return;\n    }\n\n    node.children.forEach(childNode => {\n      childNode.innerScope = { ...node.innerScope };\n      processNode(childNode, json);\n    })\n    node.content = joinContent(node.children);\n  },\n}\n\n// the legal attributes for each element\nconst nodeAttributes = {\n  insert      : [ 'path', 'jsonPath', 'rawJson' ],\n  data        : [ 'jsonPath', 'rawJson', 'default' ],\n  jsonInsert  : [ 'jsonPath', 'default' ],\n  wrap        : [ 'path', 'jsonPath', 'rawJson' ],\n  middle      : [  ],\n  each        : [ 'count', 'jsonPath', 'rawJson' ],\n  if          : [ 'jsonPath', 'rawJson' ],\n  textContent : [  ],\n}\n\n// Splits a string into an array where special tags are on their own\n// can optionally only split it up based on a particular tag\nconst splitContent = (content, tag) => {\n  let arr = [],\n      openNdx = -1,\n      closeNdx = -1,\n      partial = \"\",\n      startPattern = tag || '<!--#',\n      endPattern = '-->';\n\n  //prime the loop\n  openNdx = content.indexOf(startPattern);\n\n  if(openNdx === -1)\n    return [content];\n\n  while(openNdx > -1) {\n    partial = content.slice(0, openNdx);\n    if(partial)\n      arr.push(partial);\n\n    content = content.slice(openNdx);\n\n    // get the closeNdx despite inner open tags\n    // openNdx-><!-- <!-- --> <!-- <!-- --> --> --><-closeNdx\n    let closeNdx = getIndexOfClosingBrace(content, startPattern, endPattern);\n\n    partial = content.slice(0, closeNdx);\n    arr.push(partial);\n    content = content.slice(closeNdx);\n\n    // get ready for next iteration\n    openNdx = content.indexOf(startPattern);\n\n    // on final pass, push the remainer of the content string\n    if(openNdx === -1)\n      arr.push(content);\n  }\n\n  // Now we have an array of tags, and content\n  return arr;\n}\n\n// Given some content (starting with a tag) find the index after the matching end tag\nconst getIndexOfClosingBrace = (content, startPattern, endPattern) => {\n  let tagDepth = 0;// when this gets to 0 we are done\n  let tmpContent = content.substr(1);\n\n\n  // prime loop by finding next start tag\n  let nextCloseNdx = tmpContent.indexOf(endPattern);\n  let nextOpenNdx = tmpContent.indexOf(startPattern);\n\n  if(nextCloseNdx ===  -1)\n    console.trace(`No Close tag for startPattern: ${startPattern} and endPattern: ${endPattern} and content: ${content}`);\n\n  // if there is a nextCloseNdx, but no openNdx, return the end of the tag.\n  if(nextOpenNdx === -1 || nextOpenNdx > nextCloseNdx)\n    return nextCloseNdx + 4; // 4 not 3 because we sliced off the '<' in content\n\n  // add 1 so we will search past the tag\n  nextOpenNdx += 1;\n  nextCloseNdx += 1;\n\n  // while current tag is not closed...\n  do {\n    let tmpOpen, tmpClosed;\n\n    // start tag is before close tag, then\n    // we can look to see if there is yet another tag nested between\n    if(nextOpenNdx > -1 && nextOpenNdx < nextCloseNdx) {\n      tmpOpen = tmpContent.substr(nextOpenNdx).indexOf(startPattern);\n      // see if we found something, and add this new index to our accumulator\n      if(tmpOpen > -1) {\n        // add 1 because we need next search to be beyond this tag\n        nextOpenNdx += tmpOpen + 2;\n        tagDepth += 1;\n      }\n      else\n        nextOpenNdx = -1;\n    }\n    else { // current close tag is before start tag\n      tmpClosed = tmpContent.substr(nextCloseNdx).indexOf(endPattern);\n      // see if we found something, and add this new index to our accumulator\n      if(tmpClosed > -1) {\n        // add 1 because we need next search to be beyond this tag\n        nextCloseNdx += tmpClosed + 1;\n        tagDepth -= 1;\n\n        if(tagDepth === 0)\n          return nextCloseNdx + 3;\n      }\n      else if(tagDepth > 0) {\n        console.error(`ERROR: there is an unclosed tag - content is ${content}`);\n        break;\n      }\n    }\n  } while(tagDepth > 0)\n\n  nextCloseNdx += 4;\n\n  if(nextCloseNdx === -1)\n    console.error(`ERROR: no closing tag! you are missing a '${endPattern}'`);\n\n  return nextCloseNdx;\n}\n\n// given a jsonObject and a path, return the data pointed at\nconst getDataFromJsonPath = (jsonPath, json) => {\n  if(jsonPath === 'this') return json;\n\n  let result = jsonPath.split('.').reduce((acc, cur) => acc ? acc[cur] : '', json)\n\n  if(!Array.isArray(result) && typeof(result) === 'object')\n    result = toSafeJsonString(result);\n\n  return result;\n}\n\n// are we on windows?\nconst isWin = /^win/.test(process.platform);\n\n// overcome the difference in *nix/windows pathing\nconst fixFilePathForOS = path =>\n  (isWin) ? path.replace(/\\//g, '\\\\') : path.replace(/\\\\/g, '/')\n\n// given the current directory and a relative path, build the complete path\n// to the relative path\nconst buildPathFromRelativePath = (cdir, fdir) => {\n  let dirChar = (isWin) ? '\\\\' : '/';\n  let dir = cdir.split(dirChar);\n  dir.pop();\n\n  fdir = fixFilePathForOS(fdir);\n\n  fdir.split(dirChar)\n    .forEach(function(e) {\n      (e === '..') ? dir.pop() : (e !== '.' && e !== '') ? dir.push(e) : void 0;\n    });\n  dir = dir.join(dirChar);\n\n  return dir;\n}\n\n//\nconst toSafeJsonString = jsonObj =>\n  JSON.stringify(jsonObj).replace(/\\'/g, \"\\\\'\").replace(/\"/g, \"'\")\n\n//\nconst processRawJson = jsonString => {\n  if(typeof(jsonString) === 'object')\n    jsonString = toSafeJsonString(jsonString);\n\n  let jsonData = {};\n  try {\n    eval('jsonData = ' + jsonString);\n  }\n  catch(e) {\n    console.error(`ERROR: Poorly formatted rawJson string:\n      ${jsonString}\n      This must be valid JavaScript.\n    `);\n  }\n\n  return jsonData;\n}\n\n// does a tag have an attribute? (attributeName=\"value\")\nconst hasTagAttribute =\n  (attr, content) => content.indexOf(attr + '=\"') > -1\n\n// get the value of an attribute (attributeName=\"value\")\nconst getTagAttribute = (attr, content) => {\n  let fndx = -1,\n      lndx = -1;\n\n  fndx = content.indexOf(attr + '=\"');\n  if(fndx === -1) {\n    console.warn(\"Warning: no tag of name `\" + attr + \"` found in the following content: `\" + content + \"`\")\n    return '';\n  }\n\n  content = content.slice(fndx + attr.length + 2);\n  lndx = content.indexOf('\"');\n  content = content.slice(0, lndx);\n  return content;\n}\n"],"sourceRoot":""}